# -*- coding: utf-8 -*-
"""Confusion_matrix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JaGtgykqVtZ3NPckKEyL3XSWStKwa7h0
"""

# Commented out IPython magic to ensure Python compatibility.
import random as rn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns
# %matplotlib inline
style.use('fivethirtyeight')
sns.set(style='whitegrid',color_codes=True)

# Mount drive first and proceed
from google.colab import drive
drive.mount('/content/gdrive')



X = np.load("/content/drive/MyDrive/data.npy")
labels = np.load("/content/drive/MyDrive/label.npy")

from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical
labelEncoder = LabelEncoder()
y = labelEncoder.fit_transform(labels)
y = to_categorical(y, 10)

from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score,confusion_matrix
from sklearn.model_selection import GridSearchCV
import tensorflow as tf

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)

print("x_train shape: ", x_train.shape)
print("x_test shape: ", x_test.shape)
print("y_train shape: ", y_train.shape)
print("y_test shape: ", y_test.shape)

from keras.models import load_model
model = load_model("/content/drive/MyDrive/Project 4/model_74.h5")

test_loss, test_acc = model.evaluate(x_test, y_test)

# getting predictions on val set.
pred=model.predict(x_test)
pred_digits=np.argmax(pred, axis=1)

# now storing some properly as well as misclassified indexes'.
i=0
prop_class=[]
mis_class=[]

for i in range(len(y_test)):
    if(np.argmax(y_test[i])==pred_digits[i]):
        prop_class.append(i)
    if(len(prop_class)==8):
        break

i=0
for i in range(len(y_test)):
    if(not np.argmax(y_test[i])==pred_digits[i]):
        mis_class.append(i)
    if(len(mis_class)==8):
        break

correct_count = 0
for i in range(len(y_test)):
    if(np.argmax(y_test[i])==pred_digits[i]):
        correct_count+=1

miss_count = 0
for i in range(len(y_test)):
    if(not np.argmax(y_test[i])==pred_digits[i]):
        miss_count+=1

print(f"Correct Predictions: {correct_count}")
print(f"Wrong Predictions: {miss_count}")

from sklearn.utils.multiclass import unique_labels
# Convert one-hot encoded labels to class indices
test_labels_indices = np.argmax(y_test, axis=1)
predictions_indices = np.argmax(pred, axis=1)

# Calculate the confusion matrix
cm = confusion_matrix(test_labels_indices, predictions_indices)

# Get class labels
classes =['Bougainvillea', 'Daffodil', 'Dahlia','Foxglove','Hibiscus','Hydrangea','Orchid','Rose','Sunflower','Tulip']
#classes = ['daffodil', 'orchid', 'tulip', 'hydrangea', 'hibiscus', 'rose', 'dahlia', 'foxglove', 'sunflower', 'bougainvillea']
class_count = len(classes)
plt.figure(figsize=(16, 8))
plt.subplot(1, 2, 1)

sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)
plt.xticks(np.arange(class_count) + .5, classes, rotation=90, fontsize=14)
plt.yticks(np.arange(class_count) + .5, classes, rotation=0, fontsize=14)
plt.xlabel("Predicted", fontsize=14)
plt.ylabel("Actual", fontsize=14)
plt.title("Confusion Matrix")

plt.show()

from sklearn.metrics import classification_report

print(classification_report(predictions_indices, test_labels_indices))